{
 "metadata": {
  "name": "",
  "signature": "sha256:1afd69b88db095e1d140deedb2a310282a474322f8fbf9708e1b1c33a304c4cc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#High-level Functionality Tests\n",
      "###compare output to cell below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run 'Functions.ipynb'\n",
      "wave_num = 3\n",
      "Config.wave_infos[wave_num].raw_data_fname = 'newWave{}.tsv'.format(wave_num)\n",
      "Config.data_dist_base = '2013-01-18-Sardinia'\n",
      "Config.graphs_dir = 'Graphs/tmp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model_name = 'RandForClf'\n",
      "model_name = 'KNeighReg'\n",
      "splits = range (10)\n",
      "features = range(90, 100, 2)\n",
      "wi = Config.wave_info(wave_num)\n",
      "\n",
      "model = ModelByModelName[model_name]\n",
      "scores_NWS = []\n",
      "lda_scores_NWS = []\n",
      "\n",
      "steps = len (splits)\n",
      "step = 0\n",
      "#p = ProgressBar(steps)\n",
      "\n",
      "for split_num in splits:\n",
      "\n",
      "    print ('----- Split {:04d} -----'.format(split_num))\n",
      "    step += 1\n",
      "\n",
      "    # Read splits from files\n",
      "    split = Split()\n",
      "    split.load_wave_train_test_RS (wave_num, split_num)\n",
      "\n",
      "    mrmr_weights = read_mrmr(wave_num, split_num)\n",
      "\n",
      "    split_NWS = Split().copy (split)\n",
      "    split_NWS.norm_weigh_sort (mrmr_weights)\n",
      "\n",
      "    split_SS = Split().copy (split)\n",
      "    split_SS.stand_sort (mrmr_weights)\n",
      "\n",
      "    split_norm = Split().copy (split).normalize (split.train_set, split.test_set)\n",
      "    split_stan = Split().copy (split).stand (split.train_set, split.test_set)\n",
      "\n",
      "    split_norm_weighted = Split().copy (split_norm).apply_weights (mrmr_weights)\n",
      "    norm_weighted_sorted_mrmr = split_norm_weighted.sort_by_weight (mrmr_weights)\n",
      "    stan_sorted_mrmr = split_stan.sort_by_weight (mrmr_weights)\n",
      "\n",
      "    print ('split_SS    == split_stan         ',np.array_equal (split_SS.train_set, split_stan.train_set), np.array_equal (split_SS.test_set, split_stan.test_set) )\n",
      "    print ('split_NWS   == split_norm_weighted',np.array_equal (split_NWS.train_set, split_norm_weighted.train_set), np.array_equal (split_NWS.test_set, split_norm_weighted.test_set) )\n",
      "\n",
      "    class_vals = split_NWS.get_class_vals()\n",
      "    score_model, lda_score_model = Score_Model(ModelByModelName['KNeighClf'], features, split_NWS)\n",
      "    score_clf, lda_score_clf = Score_Clf(ModelByModelName['KNeighClf'], features, class_vals, split_NWS)\n",
      "    print ('score_model == score_clf          ',np.array_equal (score_model, score_clf),np.array_equal (lda_score_model, lda_score_clf))\n",
      "\n",
      "    score_model, lda_score_model = Score_Model(ModelByModelName['KNeighReg'], features, split_NWS)\n",
      "    score_reg, lda_score_reg = Score_Reg(ModelByModelName['KNeighReg'], features, split_NWS)\n",
      "    print ('score_model == score_reg          ',np.array_equal (score_model, score_reg),np.array_equal (lda_score_model, lda_score_reg))\n",
      "\n",
      "    score_NWS, lda_score_NWS = Score_Model(model, features, split_NWS)\n",
      "    scores_NWS.append(score_NWS)\n",
      "    lda_scores_NWS.append(lda_score_NWS)\n",
      "\n",
      "    print ('Score_Model {} mRMR (W{},S{}) Norm&Weigh LDA: {:.5f} @ {:3d}; No LDA: {:.5f} @ {:3d}'.format(\n",
      "        model_name,wave_num,split_num,\n",
      "        np.nanmax(lda_score_NWS),features[np.nanargmax(lda_score_NWS)],\n",
      "        np.nanmax(score_NWS),features[np.nanargmax(score_NWS)]))\n",
      "\n",
      "print ('------------------'.format(split_num))\n",
      "avg_score_NWS = Average_Score(scores_NWS)\n",
      "lda_avg_score_NWS = Average_Score(lda_scores_NWS)\n",
      "print ('Avg Score_Model {} mRMR (W{},S{}-{}) Norm&Weigh LDA: {:.5f} @ {:3d}; No LDA: {:.5f} @ {:3d}'.format(\n",
      "    model_name,wave_num,splits[0],splits[-1],\n",
      "    np.nanmax(lda_avg_score_NWS),features[np.nanargmax(lda_avg_score_NWS)],\n",
      "    np.nanmax(avg_score_NWS),features[np.nanargmax(avg_score_NWS)]))\n",
      "    \n",
      "#p.animate (step)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "----- Split 0000 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S0) Norm&Weigh LDA: 0.87667 @  98; No LDA: 0.86067 @  92"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0001 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S1) Norm&Weigh LDA: 0.87611 @  90; No LDA: 0.85049 @  98"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0002 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S2) Norm&Weigh LDA: 0.89388 @  92; No LDA: 0.87480 @  92"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0003 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S3) Norm&Weigh LDA: 0.90925 @  92; No LDA: 0.84136 @  96"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0004 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S4) Norm&Weigh LDA: 0.87478 @  94; No LDA: 0.85591 @  92"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0005 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S5) Norm&Weigh LDA: 0.89237 @  90; No LDA: 0.87140 @  92"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0006 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S6) Norm&Weigh LDA: 0.90787 @  90; No LDA: 0.87289 @  96"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0007 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S7) Norm&Weigh LDA: 0.90624 @  92; No LDA: 0.85976 @  96"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0008 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S8) Norm&Weigh LDA: 0.88152 @  96; No LDA: 0.85595 @  98"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----- Split 0009 -----\n",
        "split_SS    == split_stan         "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "split_NWS   == split_norm_weighted True True\n",
        "score_model == score_clf          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "score_model == score_reg          "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True\n",
        "Score_Model KNeighReg mRMR (W1,S9) Norm&Weigh LDA: 0.89758 @  98; No LDA: 0.86290 @  92"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "------------------\n",
        "Avg Score_Model KNeighReg mRMR (W1,S0-9) Norm&Weigh LDA: 0.88957 @  90; No LDA: 0.85952 @  96\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python3.4/site-packages/sklearn/lda.py:161: UserWarning: Variables are collinear\n",
        "  warnings.warn(\"Variables are collinear\")\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Previous test run - wave_num = 1, newWave1.tsv\n",
      "    ----- Split 0000 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S0) Norm&Weigh LDA: 0.87667 @  98; No LDA: 0.86067 @  92\n",
      "    ----- Split 0001 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S1) Norm&Weigh LDA: 0.87611 @  90; No LDA: 0.85049 @  98\n",
      "    ----- Split 0002 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S2) Norm&Weigh LDA: 0.89388 @  92; No LDA: 0.87480 @  92\n",
      "    ----- Split 0003 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S3) Norm&Weigh LDA: 0.90925 @  92; No LDA: 0.84136 @  96\n",
      "    ----- Split 0004 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S4) Norm&Weigh LDA: 0.87478 @  94; No LDA: 0.85591 @  92\n",
      "    ----- Split 0005 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S5) Norm&Weigh LDA: 0.89237 @  90; No LDA: 0.87140 @  92\n",
      "    ----- Split 0006 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S6) Norm&Weigh LDA: 0.90787 @  90; No LDA: 0.87289 @  96\n",
      "    ----- Split 0007 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S7) Norm&Weigh LDA: 0.90624 @  92; No LDA: 0.85976 @  96\n",
      "    ----- Split 0008 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S8) Norm&Weigh LDA: 0.88152 @  96; No LDA: 0.85595 @  98\n",
      "    ----- Split 0009 -----\n",
      "    split_SS    == split_stan          True True\n",
      "    split_NWS   == split_norm_weighted True True\n",
      "    score_model == score_clf           True True\n",
      "    score_model == score_reg           True True\n",
      "    Score_Model KNeighReg mRMR (W1,S9) Norm&Weigh LDA: 0.89758 @  98; No LDA: 0.86290 @  92\n",
      "    ------------------\n",
      "    Avg Score_Model KNeighReg mRMR (W1,S0-9) Norm&Weigh LDA: 0.88957 @  90; No LDA: 0.85952 @  96\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check that the data is binned the same way regardless of the row order in the data file\n",
      "# newWave1.csv is ordered, whereas 2013-12-18-Sardinia-CleanUp-Data-Wave1.tsv is in distribution order\n",
      "%run 'Functions.ipynb'\n",
      "\n",
      "Config.data_dist_base = '2013-12-18-Sardinia-CleanUp-Data'\n",
      "Config.wave_info(1).raw_data_fname = 'newWave1.csv'\n",
      "Config.wave_data_file_ext = 'csv'\n",
      "Config.wave_data_file_delim = ','\n",
      "\n",
      "wd1 = Config.wave_data(1)\n",
      "Config.wave_info(1).wave_data = None\n",
      "\n",
      "Config.data_dist_base = '2013-12-18-Sardinia-CleanUp-Data'\n",
      "Config.wave_info(1).raw_data_fname = '2013-12-18-Sardinia-CleanUp-Data-Wave1.tsv'\n",
      "Config.wave_data_file_ext = 'tsv'\n",
      "Config.wave_data_file_delim = '\\t'\n",
      "wd2 = Config.wave_data(1)\n",
      "Config.wave_info(1).wave_data = None\n",
      "\n",
      "for idx in range (0,len(wd1.data_class_views)):\n",
      "    print ('len( wd1[{}]) == len (wd2[{}]) == {}'.format (idx,idx,\n",
      "        len(wd1.data_class_views[idx]) == len(wd2.data_class_views[idx])))\n",
      "print()\n",
      "\n",
      "colnames = ['id_individual','Age','exmHeight','pwv']\n",
      "for colname in colnames:\n",
      "    wd1_col_idx = wd1.col_names.tolist().index(colname)\n",
      "    wd2_col_idx = wd2.col_names.tolist().index(colname)\n",
      "\n",
      "    print (\"checking equivalency of column {} ({} {})\".format(colname,wd1_col_idx,wd2_col_idx))\n",
      "    for idx in range (0,len(wd1.data_class_views)):\n",
      "        set1 = set(wd1.data_class_views[idx][:,wd1_col_idx].tolist())\n",
      "        set2 = set(wd2.data_class_views[idx][:,wd2_col_idx].tolist())\n",
      "        print ('set1[{}]) == set2[{}]) == {}'.format (idx,idx, set1 == set2))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reading data from  data/2013-12-18-Sardinia-CleanUp-Data/newWave1.csv\n",
        "reading data from "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " data/2013-12-18-Sardinia-CleanUp-Data/2013-12-18-Sardinia-CleanUp-Data-Wave1.tsv\n",
        "len( wd1[0]) == len (wd2[0]) == True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "len( wd1[1]) == len (wd2[1]) == True\n",
        "len( wd1[2]) == len (wd2[2]) == True\n",
        "len( wd1[3]) == len (wd2[3]) == True\n",
        "len( wd1[4]) == len (wd2[4]) == True\n",
        "len( wd1[5]) == len (wd2[5]) == True\n",
        "len( wd1[6]) == len (wd2[6]) == True\n",
        "len( wd1[7]) == len (wd2[7]) == True\n",
        "len( wd1[8]) == len (wd2[8]) == True\n",
        "len( wd1[9]) == len (wd2[9]) == True\n",
        "len( wd1[10]) == len (wd2[10]) == True\n",
        "len( wd1[11]) == len (wd2[11]) == True\n",
        "len( wd1[12]) == len (wd2[12]) == True\n",
        "\n",
        "checking equivalency of column id_individual (0 0)\n",
        "set1[0]) == set2[0]) == True\n",
        "set1[1]) == set2[1]) == True\n",
        "set1[2]) == set2[2]) == True\n",
        "set1[3]) == set2[3]) == True\n",
        "set1[4]) == set2[4]) == True\n",
        "set1[5]) == set2[5]) == True\n",
        "set1[6]) == set2[6]) == True\n",
        "set1[7]) == set2[7]) == True\n",
        "set1[8]) == set2[8]) == True\n",
        "set1[9]) == set2[9]) == True\n",
        "set1[10]) == set2[10]) == True\n",
        "set1[11]) == set2[11]) == True\n",
        "set1[12]) == set2[12]) == True\n",
        "\n",
        "checking equivalency of column Age (1 1)\n",
        "set1[0]) == set2[0]) == True\n",
        "set1[1]) == set2[1]) == True\n",
        "set1[2]) == set2[2]) == True\n",
        "set1[3]) == set2[3]) == True\n",
        "set1[4]) == set2[4]) == True\n",
        "set1[5]) == set2[5]) == True\n",
        "set1[6]) == set2[6]) == True\n",
        "set1[7]) == set2[7]) == True\n",
        "set1[8]) == set2[8]) == True\n",
        "set1[9]) == set2[9]) == True\n",
        "set1[10]) == set2[10]) == True\n",
        "set1[11]) == set2[11]) == True\n",
        "set1[12]) == set2[12]) == True\n",
        "\n",
        "checking equivalency of column exmHeight (51 51)\n",
        "set1[0]) == set2[0]) == True\n",
        "set1[1]) == set2[1]) == True\n",
        "set1[2]) == set2[2]) == True\n",
        "set1[3]) == set2[3]) == True\n",
        "set1[4]) == set2[4]) == True\n",
        "set1[5]) == set2[5]) == True\n",
        "set1[6]) == set2[6]) == True\n",
        "set1[7]) == set2[7]) == True\n",
        "set1[8]) == set2[8]) == True\n",
        "set1[9]) == set2[9]) == True\n",
        "set1[10]) == set2[10]) == True\n",
        "set1[11]) == set2[11]) == True\n",
        "set1[12]) == set2[12]) == True\n",
        "\n",
        "checking equivalency of column pwv (78 78)\n",
        "set1[0]) == set2[0]) == True\n",
        "set1[1]) == set2[1]) == True\n",
        "set1[2]) == set2[2]) == True\n",
        "set1[3]) == set2[3]) == True\n",
        "set1[4]) == set2[4]) == True\n",
        "set1[5]) == set2[5]) == True\n",
        "set1[6]) == set2[6]) == True\n",
        "set1[7]) == set2[7]) == True\n",
        "set1[8]) == set2[8]) == True\n",
        "set1[9]) == set2[9]) == True\n",
        "set1[10]) == set2[10]) == True\n",
        "set1[11]) == set2[11]) == True\n",
        "set1[12]) == set2[12]) == True\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Using different data distributions\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run 'Functions.ipynb'\n",
      "Config.set_data_dist_base ('2013-12-18')\n",
      "wavenum = 3\n",
      "wd = Config.wave_data(wavenum)\n",
      "print (wd)\n",
      "\n",
      "Config.set_data_dist_base ('2014-08-26')\n",
      "wavenum = 3\n",
      "wd = Config.wave_data(wavenum)\n",
      "print (wd)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Setting Config.data_dist_base to \"2013-12-18-Sardinia-CleanUp-Data\"\n",
        "reading data from  data/2013-12-18-Sardinia-CleanUp-Data/2013-12-18-Sardinia-CleanUp-Data-Wave3.tsv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2410 samples, 122 features, 12 classes\n",
        "  22.5  27.5  32.5  37.5  42.5  47.5  52.5  57.5  62.5  67.5  72.5  77.5\n",
        "  95   146   203   246   291   276   243   249   201   191   134    90  \n",
        "\n",
        "Setting Config.data_dist_base to \"2014-08-26-Sardinia\"\n",
        "reading data from  data/2014-08-26-Sardinia/2014-08-26-Sardinia-Wave3.tsv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4033 samples, 442 features, 13 classes\n",
        "  20.5  25.5  30.5  35.5  40.5  45.5  50.5  55.5  60.5  65.5  70.5  75.5  80.5\n",
        " 144   260   323   363   421   457   412   380   363   312   254   188   115  \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Previous run result\n",
      "\n",
      "    Setting Config.data_dist_base to \"2013-12-18-Sardinia-CleanUp-Data\"\n",
      "    reading data from  data/2013-12-18-Sardinia-CleanUp-Data/2013-12-18-Sardinia-CleanUp-Data-Wave3.tsv\n",
      "    2410 samples, 122 features, 12 classes\n",
      "      22.5  27.5  32.5  37.5  42.5  47.5  52.5  57.5  62.5  67.5  72.5  77.5\n",
      "      95   146   203   246   291   276   243   249   201   191   134    90  \n",
      "\n",
      "    Setting Config.data_dist_base to \"2014-08-26-Sardinia\"\n",
      "    reading data from  data/2014-08-26-Sardinia/2014-08-26-Sardinia-Wave3.tsv\n",
      "    4033 samples, 442 features, 13 classes\n",
      "      20.5  25.5  30.5  35.5  40.5  45.5  50.5  55.5  60.5  65.5  70.5  75.5  80.5\n",
      "     144   260   323   363   421   457   412   380   363   312   254   188   115  \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}